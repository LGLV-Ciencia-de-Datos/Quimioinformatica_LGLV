{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LGLV/APS-Failure-at-Scania-Trucks-Data-Set/blob/main/6_2_Espacio_Qu%C3%ADmico_PCA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jq5mPco1VWTX"
      },
      "source": [
        "# Análisis de componentes principales (PCA)\n",
        "\n",
        "\n",
        "---\n",
        "Realizó: Ana Chávez, Fernanda Saldívar, Armando Rufino y Hector Ortíz\n",
        "\n",
        "Contacto: anachavez3026@gmail.com, fer.saldivarg@gmail.com"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qd0Wj_zMv45L"
      },
      "outputs": [],
      "source": [
        "from IPython.utils import io\n",
        "import tqdm.notebook\n",
        "import os, sys, random\n",
        "total = 100\n",
        "with tqdm.notebook.tqdm(total=total) as pbar:\n",
        "    with io.capture_output() as captured:\n",
        "      # Instalar rdkit\n",
        "      !pip -q install rdkit.pypi==2021.9.4\n",
        "      pbar.update(20)\n",
        "      # Instalar Pillow\n",
        "      !pip -q install Pillow\n",
        "      pbar.update(40)\n",
        "      # Instalar molplotly\n",
        "      !pip install molplotly\n",
        "      pbar.update(60)\n",
        "      # Instalar jupyter-dash\n",
        "      !pip install jupyter-dash\n",
        "      pbar.update(80)\n",
        "      # Instalar el diseño de aplicación dash\n",
        "      !pip install dash-bootstrap-components\n",
        "      pbar.update(100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RqCBKiFa-JHZ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import dash_bootstrap_components as dbc\n",
        "from sys import argv\n",
        "\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import Descriptors\n",
        "from rdkit.Chem import rdMolDescriptors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bHv0YyukugH"
      },
      "source": [
        "* RDKIT: https://www.rdkit.org/docs/GettingStartedInPython.html\n",
        "* PANDAS: https://pandas.pydata.org/\n",
        "* NUMPY: https://numpy.org/\n",
        "* SKLEARN: https://scikit-learn.org/stable/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xQtKDtUWyAlb"
      },
      "outputs": [],
      "source": [
        "# Leer bases de datos\n",
        "#BIOFACQUIM\n",
        "url_biofacquim = \"https://raw.githubusercontent.com/DIFACQUIM/Cursos/main/Datasets/BIOFACQUIM.V2_curada.csv\"\n",
        "BIOFACQUIM = pd.read_csv(url_biofacquim)\n",
        "BIOFACQUIM.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vpZp9aEcz9m_"
      },
      "outputs": [],
      "source": [
        "# Leer bases de datos\n",
        "#FDA\n",
        "url_fda = \"https://raw.githubusercontent.com/DIFACQUIM/Cursos/main/Datasets/FDA_2022_july_05_curada.csv\"\n",
        "FDA = pd.read_csv(url_fda)\n",
        "FDA.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BsPY1kr2z_h9"
      },
      "outputs": [],
      "source": [
        "# Leer base de datos\n",
        "#DNMT1\n",
        "url_dnmt1 = \"https://raw.githubusercontent.com/DIFACQUIM/Cursos/main/Datasets/DNMT1_curada.csv\"\n",
        "DNMT1 = pd.read_csv(url_dnmt1)\n",
        "DNMT1.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c7HJwW6DFOns"
      },
      "outputs": [],
      "source": [
        "# Ejemplo de smiles\n",
        "smi = list(FDA[\"SMILES\"])[150]\n",
        "print(smi)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "95HvY5CTJ17R"
      },
      "outputs": [],
      "source": [
        "# Ejemplo de una molécula\n",
        "from rdkit.Chem.Draw import IPythonConsole, MolsToGridImage\n",
        "mol = Chem.MolFromSmiles(smi)\n",
        "mol"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ru0jCw3U43L6"
      },
      "outputs": [],
      "source": [
        "# Ver columnas\n",
        "print(FDA.columns)\n",
        "print(BIOFACQUIM.columns)\n",
        "print(DNMT1.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7zx6RzbH5sRs"
      },
      "outputs": [],
      "source": [
        "# Seleccionar columnas\n",
        "FDA = FDA[['ID', 'NEW_SMILES', \"Data set\"]]\n",
        "BIOFACQUIM = BIOFACQUIM[['ID', 'SMILES', \"Data set\"]]\n",
        "DNMT1 = DNMT1[['ID', 'SMILES', \"Data set\"]]\n",
        "# Cambiar nombre a columnas\n",
        "FDA.columns = [\"ID\", \"SMILES\", \"Data set\"]\n",
        "BIOFACQUIM.columns = ['ID',  'SMILES', \"Data set\"]\n",
        "DNMT1.columns = [\"ID\", \"SMILES\", \"Data set\"]\n",
        "FDA.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yjlUY-F-4mF8"
      },
      "outputs": [],
      "source": [
        "# Unir (concatenar) bases de datos\n",
        "DATA = pd.concat([FDA, BIOFACQUIM, DNMT1], axis=0).reset_index(drop=True)\n",
        "DATA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wIXVFYhs-L2-"
      },
      "outputs": [],
      "source": [
        "# Generar descriptores\n",
        "DATA[\"HBA\"] = [Descriptors.NumHAcceptors(y) for y in (Chem.MolFromSmiles(x) for x in DATA[\"SMILES\"])]\n",
        "DATA[\"HBD\"] = [Descriptors.NumHDonors(y) for y in (Chem.MolFromSmiles(x) for x in DATA[\"SMILES\"])]\n",
        "DATA[\"RB\"] = [Descriptors.NumRotatableBonds(y) for y in (Chem.MolFromSmiles(x) for x in DATA[\"SMILES\"])]\n",
        "DATA[\"LogP\"] = [Descriptors.MolLogP(y) for y in (Chem.MolFromSmiles(x) for x in DATA[\"SMILES\"])]\n",
        "DATA[\"TPSA\"] = [Descriptors.TPSA(y) for y in (Chem.MolFromSmiles(x) for x in DATA[\"SMILES\"])]\n",
        "DATA[\"MW\"] = [Descriptors.MolWt(y) for y in (Chem.MolFromSmiles(x) for x in DATA[\"SMILES\"])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MllPGfDDvNd9"
      },
      "outputs": [],
      "source": [
        "DATA.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "45kBeoS5ARdA"
      },
      "outputs": [],
      "source": [
        "dataset = DATA[[\"Data set\", \"HBA\", \"HBD\", \"RB\", \"LogP\", \"TPSA\", \"MW\"]]\n",
        "dataset.head(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GPp6LwElJSH"
      },
      "source": [
        "### Generar PCA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fUEqAOWhmXI"
      },
      "source": [
        "#### 1. Dividir base de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M5Wm_aM1wGbB"
      },
      "outputs": [],
      "source": [
        "#Dividir matriz\n",
        "data = dataset.iloc[:,1:7].values # Seleccionar columnas con descriptores\n",
        "label = dataset.iloc[:,0].values # Seleccionar el nombre de la base de datos(label) de las columnas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3FPsdmoNBz7G"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame(data).head(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PCx5vP3YV5C"
      },
      "source": [
        "#### 2. Normalizar datos\n",
        "StandardScaler() estandariza las características del conjunto de datos en la escala de la unidad (media = 0 y varianza = 1) que es un requisito para el rendimiento óptimo de muchos algoritmos de aprendizaje automático."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qZf9hAEPBBK9"
      },
      "outputs": [],
      "source": [
        "# Normalizar datos\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "data_std = StandardScaler().fit_transform(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fz8A1tuej7oy"
      },
      "source": [
        "#### 3. Entrenar modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qASDTPcXjePY"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components=2)\n",
        "pca_results = pca.fit_transform(data_std)\n",
        "pca_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rqUGMfDzpiwv"
      },
      "outputs": [],
      "source": [
        "# Seleccionar impormación complementaria\n",
        "label = DATA[[\"Data set\", \"ID\", \"SMILES\"]]\n",
        "label = label.to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pJvhm7YSpn47"
      },
      "outputs": [],
      "source": [
        "# Concatenar arrays de numpy\n",
        "arr = np.concatenate((label, pca_results), axis = 1)\n",
        "# Crear un nuevo dataframe\n",
        "pca_dataset = pd.DataFrame(data=arr, columns = ['Data set',\"ID\", \"SMILES\",'component1', 'component2'])\n",
        "pca_dataset.head(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGGdbX2vkLxx"
      },
      "source": [
        "Al realizar el método de PCA, hay una pérdida de correlación con cada componente, por esto es necesario poder identificar la cantidad de correlación que poseemos para nuestras representaciones visuales, pudiendo determinar si estas serán relevantes o no por la cantidad de correlación que posean con la muestra original."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finalmente, se pretende visualizar la varianza explicada por cada componente principal utilizando una gráfica de barras y una gráfica escalonada. La variable \"cum_sum_eigenvalues\" es un arreglo numpy que contiene la suma acumulativa de la varianza explicada por cada componente principal. Luego, se utiliza la función \"plt.bar()\" para crear la gráfica de barras de la varianza explicada para cada componente principal y la función \"plt.step()\" para crear la gráfica escalonada de la varianza explicada acumulada. Finalmente, se ajustan los ejes y se muestran ambas gráficas utilizando \"plt.tight_layout()\" y \"plt.show()\"."
      ],
      "metadata": {
        "id": "TcQa7IvCKzzq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TRdxLvPtkQKT"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "sc.fit(data)\n",
        "X_train_std = sc.transform(data)\n",
        "#X_test_std = sc.transform(X_test)\n",
        "# Instantiate PCA\n",
        "pca = PCA()\n",
        "\n",
        "# Determine transformed features\n",
        "X_train_pca = pca.fit_transform(X_train_std)\n",
        "\n",
        "# Determine explained variance using explained_variance_ration_ attribute\n",
        "exp_var_pca = pca.explained_variance_ratio_\n",
        "#\n",
        "# Cumulative sum of eigenvalues; This will be used to create step plot\n",
        "# for visualizing the variance explained by each principal component.\n",
        "cum_sum_eigenvalues = np.cumsum(exp_var_pca)\n",
        "#\n",
        "# Create the visualization plot\n",
        "import matplotlib.pyplot as plt\n",
        "plt.bar(range(0,len(exp_var_pca)), exp_var_pca, alpha=0.5, align='center', label='Individual explained variance')\n",
        "plt.step(range(0,len(cum_sum_eigenvalues)), cum_sum_eigenvalues, where='mid',label='Cumulative explained variance')\n",
        "plt.ylabel('Explained variance ratio')\n",
        "plt.xlabel('Principal component index')\n",
        "plt.legend(loc='best')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i0opzUk_lQ4G"
      },
      "outputs": [],
      "source": [
        "pca_dataset.head(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZoLj9UKykb8-"
      },
      "source": [
        "Ahora vamos a usar **seaborn** para hacer el gráfico de PCA. En este gráfico, los puntos de datos similares deberían estar más cerca, formando clusters. Para este conjunto de datos nos gustaría ver a las distintas bases de datos, formando grupos distintos.\n",
        "(Al hacer el gráfico de dispersión, el parámetro `DataBase` se corresponde con el color de los puntos)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "set(list(pca_dataset[\"Data set\"]))"
      ],
      "metadata": {
        "id": "Dsu5MOdwGbcJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xALOgjAHkdsv"
      },
      "outputs": [],
      "source": [
        "#Graficar\n",
        "import plotly.express as px\n",
        "import molplotly\n",
        "fig_pca = px.scatter(pca_dataset,\n",
        "                            x='component1',\n",
        "                            y='component2',\n",
        "                            #symbol='Minimum Degree',\n",
        "                            color='Data set',\n",
        "                            color_discrete_sequence=[\"indigo\", \"green\", 'orange',],\n",
        "                            title='PCA',\n",
        "                            labels={'PC1': 'PC_1',\n",
        "                                    'PC2': 'PC_2'},\n",
        "                            width=700,\n",
        "                            height=500)\n",
        "app_marker = molplotly.add_molecules(fig=fig_pca,\n",
        "                                         df=pca_dataset,\n",
        "                                         smiles_col='SMILES',\n",
        "                                         title_col='ID',\n",
        "                                         color_col='Data set'\n",
        "                                        )\n",
        "#fig_pca.show()\n",
        "#app_marker.run_server(mode='inline', port=8060, height=1000)\n",
        "app_marker.run(port=8060)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WRxsrz0mxEeI"
      },
      "outputs": [],
      "source": [
        "#============================================================================#"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Para saber más:\n",
        "\n",
        "* Medina-Franco JL, Sánchez-Cruz N, López-López E, Díaz-Eufracio BI. Progress on open chemoinformatic tools for expanding and exploring the chemical space. J Comput Aided Mol Des. 2022, 36, 341-354. DOI: [10.1007/s10822-021-00399-1](https://link.springer.com/article/10.1007/s10822-021-00399-1).\n",
        "* Medina-Franco JL, Chávez-Hernández AL, López-López E, Saldívar-González FI. Chemical Multiverse: An Expanded View of Chemical Space. Mol Inform. 2022, 41, e2200116. DOI: [10.1002/minf.202200116](https://onlinelibrary.wiley.com/doi/10.1002/minf.202200116).\n",
        "* Greener JG, Kandathil SM, Moffat L, Jones DT. A guide to machine learning for biologists. Nat Rev Mol Cell Biol. 2022, 23, 40-55. DOI:[10.1038/s41580-021-00407-0](https://www.nature.com/articles/s41580-021-00407-0).\n",
        "* Bender A, Schneider N, Segler M, Patrick Walters W, Engkvist O, Rodrigues T. Evaluation guidelines for machine learning tools in the chemical sciences. Nat Rev Chem. 2022, 6, 428-442. DOI: [10.1038/s41570-022-00391-9](https://www.nature.com/articles/s41570-022-00391-9)."
      ],
      "metadata": {
        "id": "uFsxKNdGdcJr"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
